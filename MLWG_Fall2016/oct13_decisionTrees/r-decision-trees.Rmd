---
title: "Decision trees for machine learning"
output: html_notebook
---

Topics

* rpart
* Caret
* SuperLearner
* h2o.ai
* mlr
* book

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. Use the latest RStudio preview release to run within RStudio.

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
# Load iris dataset.
data(iris)

# Review data structure.
str(iris)

# Review species distribution.
table(iris$Species, useNA = "ifany")
```

```{r}
# install rpart first if you don't already have it.
# rpart = recursive partitioning and regression trees (aka decision trees)
library(rpart)

# Review package help and vignette if available.
# HINT: vignette covers all of this in much better detail.
help(package = "rpart")

# Review main decision tree function.
?rpart

# Review the configuration options for trees.
?rpart.control

# We need to set a seed due to randomness in the cross-validation.
set.seed(1)

# Fit a classification decision tree to predict Species using all other variables.
# We don't need to specify method="class" because Species is a factor variable.
# We specify 10 cross-validation folds to determine the best complexity.
# Minbucket is the minimum number of observations in a node.
tree_model = rpart(Species ~ ., data = iris,
            control = rpart.control(xval = 10, minbucket = 5, cp = 0))

# Display the decision tree in text form.
tree_model

# Plot tree graphically.
plot(tree_model, compress = T)
# We have to add the plot text manually for some reason.
text(tree_model, use.n = T)
```

Wow, this is one of the worst plots I've ever seen! Hard to get much worse than that.

Let's tree a better decision tree plotting package.

```{r}
# Install from CRAN if you don't already have this:
library(rpart.plot)

rpart.plot(tree_model)

# What other settings can we modify?
?rpart.plot

# Review the vignette if interested.
help(package = "rpart.plot")

# Another way to plot it.
library(partykit)
plot(as.party(tree_model))

# fancyRpartPlot() in the rattle package is also good.

```

We can dig into the details of the tree a bit more.

```{r}
# Review accuracy for different complexity parameters.
# When nsplits = 0 we have 0 nodes and are just guessing the most common class.
# When nsplits is large we have 1  + # splits nodes and each node is its own prediction.
printcp(tree_model)

# Save the complexit parameter table.
cp_table = printcp(tree_model)

# Review structure of the cp table.
str(cp_table)

# Which row has minimum cross-validation error?
# Alternatively we could choose the tree within 1 SD of the minimum.
best_row = cp_table[which.min(cp_table[, "xerror"]), ]
best_row
best_row["CP"]

# Get all the details on the tree.
summary(tree_model, cp = best_row["CP"])

# Prune to the optimal complexity parameter (no change in this case).
tree_model = prune(tree_model, cp = best_row["CP"])

tree_model
```

We did not create a separate holdout or test set, so let's predict back on the original data.

```{r}
predictions = predict(tree_model, iris)
summary(predictions)

# How do the predictions look compared to the outcome data?
data.frame(iris$Species, predictions)

# This is an optimistic view because the model was built on this same data.
# With a random holdout set we would get a more realistic view of accuracy.

```

## Regression

Quick regression example.
```{r}
# This data is in the rpart package.
data(car90)

# Review structure of dataset.
str(car90)

# Set seed due to cross-validation randomness.
set.seed(1)

# Predict price using most other fields.
# Remove a few fields that are too predictive (rim) or too many categories.
reg_tree = rpart(Price ~ ., data = car90[, !names(car90) %in% c("Rim", "Tires", "Model2")])

# How'd it go?
reg_tree

# Review complexity parameter options.
printcp(reg_tree)

# Visualize results across complexity parameter.
rsq.rpart(reg_tree)

# Save the complexit parameter table.
cp_table = printcp(reg_tree)

# Which row has minimum cross-validation error?
best_row = cp_table[which.min(cp_table[, "xerror"]), ]
best_row
best_row["CP"]

# Review summary with the best complexity parameter.
summary(reg_tree, cp = best_row["CP"])

# Prune our tree back to the best complexity parameter.
# Note that in this case no real pruning is needed, because
# the full tree is the best.
reg_tree = prune(reg_tree, cp = best_row["CP"])

# Visualize our final tree.
rpart.plot(reg_tree)

```

# Caret

```{r}
library(caret)

# Nice and simple - using default settings for everything.
# caret tries 3 complexity parameters by default, but tuneLength customizes that.
model = train(Species ~ ., data = iris, method = "rpart", tuneLength = 5)

# We see again that cp= 0 gives us the best accuracy.
model

# Use the handle built-in caret plotting.
plot(model)

# Look at the final model object (rpart).
model$finalModel
```

# SuperLearner

SuperLearner unfortunately cannot do multiple-class classification (yet) so let's convert to a binary classification problem.

```{r}

# Review 
table(iris$Species)

# Copy into a new dataframe.
data = iris

# Convert Species to a binary indicator for setosa.
data$Species = 1*(data$Species == "versicolor")

# Confirm distribution of modified outcome variable.
table(data$Species, iris$Species, useNA = "ifany")

library(SuperLearner)

set.seed(1)

sl = SuperLearner(X = data[, -5], Y = data$Species, family = binomial(),
                  SL.library = c("SL.mean", "SL.rpart"))
sl

# Review the raw rpart object.
sl$fitLibrary$SL.rpart_All$object

# Use our nice plotting library.
rpart.plot::rpart.plot(sl$fitLibrary$SL.rpart_All$object)

```

# h2o.ai

We can get close to a single decision tree by using randomForest in h2o. We set RF to fit a single decision tree and to search all variables at each split. It will not be exactly the same due to boostrap sampling but will be similar.

```{r}
library(h2o)

# Start h2o backend.
h2o.init()

# Load iris data into h2o.
iris_h2o = h2o.uploadFile(path = system.file("extdata", "iris_wheader.csv", package="h2o"),
                          destination_frame = "iris_h2o")

# Confirm it loaded correctly.
summary(iris_h2o)

# Specify x and y by the column indices.
# Set ntree to 1, and mtries to # of covariates.
# Seed only reproducible when running single-threaded.
iris_tree = h2o.randomForest(y = 5, x = 1:4, training_frame = iris_h2o,
                             ntrees = 1, mtries = 4, seed = 1)

# Review results.
iris_tree

summary(iris_tree)

# Review variable importance.
h2o.varimp(iris_tree)

# Plot variable importance - nice.
h2o.varimp_plot(iris_tree)

# Shutdown h2o backend.
h2o.shutdown(prompt = F)
```

# mlr

```{r}
library(mlr)

# Generate the task for multiple classification (also works for binary).
task = makeClassifTask(data = iris, target = "Species")

# Get the number of observations
n = getTaskSize(task)

# Generate the learners.
learners = list(makeLearner("classif.rpart", id = "rpart", predict.type = "prob"))

# 5-fold cross-validation, stratifying on Y to ensure balance across folds.
# could use stratify.cols to stratify on certain important covariates.
rdesc = makeResampleDesc("CV", iters = 5, stratify = T)

# Fit model across cross-validation folds and calculate the performance.
result = benchmark(learners, task, rdesc, measures = list(acc, mmce))

# MMCE = mean misclassification error (i.e. 1 - accuracy)
result

# Plot the results. Generally we would plot multiple models here.
plotBMRBoxplots(result, measure = acc)
```


# Decision tree references

This book has nearly everything you would want to know about the theory of decision trees:

Breiman, L., Friedman, J., Stone, C. J., & Olshen, R. A. (1984). Classification and regression trees. CRC press.

The book has 32,000 citations according to Google Scholar. Not too shabby! Breiman and Stone were both Berkeley professors, and Breiman invented Random Forest, bagging, and some of the SuperLearner theory. Friedman is at Stanford and invented many other machine learning algorithms, particularly gradient boosted machines GBM) and multivariate adaptive regression splines (MARS). Olshen is also at Stanford.
