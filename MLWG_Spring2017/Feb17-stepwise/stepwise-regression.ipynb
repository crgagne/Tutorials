{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepwise Regression\n",
    "\n",
    "### Forward selection with adjusted R-squared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code from http://planspace.org/20150423-forward_selection_with_statsmodels/\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def forward_selection(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)  # remove dependent variable\n",
    "    selected = []  # to hold selected independent variables\n",
    "    current_score, best_new_score = 0.0, 0.0  # set scores to 0 before iterations\n",
    "    while remaining and current_score == best_new_score:  # while there are still independent vars to test\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:  # each possible ind. var.\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))  # add to already selected ind. vars\n",
    "            \n",
    "            score = smf.ols(formula, data).fit().rsquared_adj  # run the reg. and get the adj. rsquared\n",
    "            scores_with_candidates.append((score, candidate))  # append the adj. rsquared and ind. var. name\n",
    "        scores_with_candidates.sort()  # sort scores low to high\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()  # assign and remove highest score and name\n",
    "        if current_score < best_new_score:  # if the new score is better than the old\n",
    "            remaining.remove(best_candidate)  # remove ind. var. from remaining\n",
    "            selected.append(best_candidate)  # add ind. var. to final selection\n",
    "            current_score = best_new_score  # make this score the new one to beat\n",
    "            \n",
    "    # if all variables were tested or the score did not improve\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))  # format the formula string for smf\n",
    "    model = smf.ols(formula, data).fit()  # fit and return the final model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `statsmodel` library prefers `pandas` data frames over `numpy` arrays as in `scikit-learn`, but luckily `pandas` has some nice methods that can read in data directly from the web. Let's grab a dataset from a Princeton class used for linear regression. The data consists \"of observations on six variables for 52 tenure-track professors in a small college.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"http://data.princeton.edu/wws509/datasets/salary.dat\"\n",
    "data = pd.read_csv(url, sep='\\\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data description: http://data.princeton.edu/wws509/datasets/#salary \n",
    "\n",
    "- sx = Sex, coded 1 for female and 0 for male\n",
    "- rk = Rank, coded\n",
    "- 1 for assistant professor,\n",
    "- 2 for associate professor, and\n",
    "- 3 for full professor\n",
    "- yr = Number of years in current rank\n",
    "- dg = Highest degree, coded 1 if doctorate, 0 if masters\n",
    "- yd = Number of years since highest degree was earned\n",
    "- sl = Academic year salary, in dollars.\n",
    "\n",
    "Used in: S. Weisberg (1985). Applied Linear Regression, Second Edition. New York: John Wiley and Sons. Page 194."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sx</th>\n",
       "      <th>rk</th>\n",
       "      <th>yr</th>\n",
       "      <th>dg</th>\n",
       "      <th>yd</th>\n",
       "      <th>sl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>25</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>35</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>13</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>22</td>\n",
       "      <td>35350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>10</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>23</td>\n",
       "      <td>28200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>full</td>\n",
       "      <td>7</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>27</td>\n",
       "      <td>26775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>19</td>\n",
       "      <td>masters</td>\n",
       "      <td>30</td>\n",
       "      <td>33696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>16</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>21</td>\n",
       "      <td>28516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>full</td>\n",
       "      <td>0</td>\n",
       "      <td>masters</td>\n",
       "      <td>32</td>\n",
       "      <td>24900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>16</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>18</td>\n",
       "      <td>31909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>13</td>\n",
       "      <td>masters</td>\n",
       "      <td>30</td>\n",
       "      <td>31850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>13</td>\n",
       "      <td>masters</td>\n",
       "      <td>31</td>\n",
       "      <td>32850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>12</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>22</td>\n",
       "      <td>27025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>15</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>19</td>\n",
       "      <td>24750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>9</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>17</td>\n",
       "      <td>28200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>9</td>\n",
       "      <td>masters</td>\n",
       "      <td>27</td>\n",
       "      <td>23712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>9</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>24</td>\n",
       "      <td>25748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>7</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>15</td>\n",
       "      <td>29342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>13</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>20</td>\n",
       "      <td>31114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>11</td>\n",
       "      <td>masters</td>\n",
       "      <td>14</td>\n",
       "      <td>24742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>10</td>\n",
       "      <td>masters</td>\n",
       "      <td>15</td>\n",
       "      <td>22906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>6</td>\n",
       "      <td>masters</td>\n",
       "      <td>21</td>\n",
       "      <td>24450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>male</td>\n",
       "      <td>assistant</td>\n",
       "      <td>16</td>\n",
       "      <td>masters</td>\n",
       "      <td>23</td>\n",
       "      <td>19175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>8</td>\n",
       "      <td>masters</td>\n",
       "      <td>31</td>\n",
       "      <td>20525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>7</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>13</td>\n",
       "      <td>27959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>female</td>\n",
       "      <td>full</td>\n",
       "      <td>8</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>24</td>\n",
       "      <td>38045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>9</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>12</td>\n",
       "      <td>24832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>5</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>18</td>\n",
       "      <td>25400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>11</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>14</td>\n",
       "      <td>24800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>female</td>\n",
       "      <td>full</td>\n",
       "      <td>5</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>25500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>3</td>\n",
       "      <td>masters</td>\n",
       "      <td>7</td>\n",
       "      <td>26182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>3</td>\n",
       "      <td>masters</td>\n",
       "      <td>17</td>\n",
       "      <td>23725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>female</td>\n",
       "      <td>assistant</td>\n",
       "      <td>10</td>\n",
       "      <td>masters</td>\n",
       "      <td>15</td>\n",
       "      <td>21600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>11</td>\n",
       "      <td>masters</td>\n",
       "      <td>31</td>\n",
       "      <td>23300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>male</td>\n",
       "      <td>assistant</td>\n",
       "      <td>9</td>\n",
       "      <td>masters</td>\n",
       "      <td>14</td>\n",
       "      <td>23713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>female</td>\n",
       "      <td>associate</td>\n",
       "      <td>4</td>\n",
       "      <td>masters</td>\n",
       "      <td>33</td>\n",
       "      <td>20690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>female</td>\n",
       "      <td>associate</td>\n",
       "      <td>6</td>\n",
       "      <td>masters</td>\n",
       "      <td>29</td>\n",
       "      <td>22450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>1</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>9</td>\n",
       "      <td>20850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>female</td>\n",
       "      <td>assistant</td>\n",
       "      <td>8</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>14</td>\n",
       "      <td>18304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>male</td>\n",
       "      <td>assistant</td>\n",
       "      <td>4</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>4</td>\n",
       "      <td>17095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>male</td>\n",
       "      <td>assistant</td>\n",
       "      <td>4</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>5</td>\n",
       "      <td>16700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>male</td>\n",
       "      <td>assistant</td>\n",
       "      <td>4</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>4</td>\n",
       "      <td>17600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>male</td>\n",
       "      <td>assistant</td>\n",
       "      <td>3</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>4</td>\n",
       "      <td>18075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>male</td>\n",
       "      <td>assistant</td>\n",
       "      <td>3</td>\n",
       "      <td>masters</td>\n",
       "      <td>11</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>male</td>\n",
       "      <td>associate</td>\n",
       "      <td>0</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>7</td>\n",
       "      <td>20999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>female</td>\n",
       "      <td>assistant</td>\n",
       "      <td>3</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>3</td>\n",
       "      <td>17250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>male</td>\n",
       "      <td>assistant</td>\n",
       "      <td>2</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>3</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>male</td>\n",
       "      <td>assistant</td>\n",
       "      <td>2</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>1</td>\n",
       "      <td>16094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>female</td>\n",
       "      <td>assistant</td>\n",
       "      <td>2</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>6</td>\n",
       "      <td>16150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>female</td>\n",
       "      <td>assistant</td>\n",
       "      <td>2</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>2</td>\n",
       "      <td>15350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>male</td>\n",
       "      <td>assistant</td>\n",
       "      <td>1</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>1</td>\n",
       "      <td>16244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>female</td>\n",
       "      <td>assistant</td>\n",
       "      <td>1</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>1</td>\n",
       "      <td>16686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>female</td>\n",
       "      <td>assistant</td>\n",
       "      <td>1</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>1</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>female</td>\n",
       "      <td>assistant</td>\n",
       "      <td>0</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>2</td>\n",
       "      <td>20300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sx         rk  yr         dg  yd     sl\n",
       "0     male       full  25  doctorate  35  36350\n",
       "1     male       full  13  doctorate  22  35350\n",
       "2     male       full  10  doctorate  23  28200\n",
       "3   female       full   7  doctorate  27  26775\n",
       "4     male       full  19    masters  30  33696\n",
       "5     male       full  16  doctorate  21  28516\n",
       "6   female       full   0    masters  32  24900\n",
       "7     male       full  16  doctorate  18  31909\n",
       "8     male       full  13    masters  30  31850\n",
       "9     male       full  13    masters  31  32850\n",
       "10    male       full  12  doctorate  22  27025\n",
       "11    male  associate  15  doctorate  19  24750\n",
       "12    male       full   9  doctorate  17  28200\n",
       "13    male  associate   9    masters  27  23712\n",
       "14    male       full   9  doctorate  24  25748\n",
       "15    male       full   7  doctorate  15  29342\n",
       "16    male       full  13  doctorate  20  31114\n",
       "17    male  associate  11    masters  14  24742\n",
       "18    male  associate  10    masters  15  22906\n",
       "19    male       full   6    masters  21  24450\n",
       "20    male  assistant  16    masters  23  19175\n",
       "21    male  associate   8    masters  31  20525\n",
       "22    male       full   7  doctorate  13  27959\n",
       "23  female       full   8  doctorate  24  38045\n",
       "24    male  associate   9  doctorate  12  24832\n",
       "25    male       full   5  doctorate  18  25400\n",
       "26    male  associate  11  doctorate  14  24800\n",
       "27  female       full   5  doctorate  16  25500\n",
       "28    male  associate   3    masters   7  26182\n",
       "29    male  associate   3    masters  17  23725\n",
       "30  female  assistant  10    masters  15  21600\n",
       "31    male  associate  11    masters  31  23300\n",
       "32    male  assistant   9    masters  14  23713\n",
       "33  female  associate   4    masters  33  20690\n",
       "34  female  associate   6    masters  29  22450\n",
       "35    male  associate   1  doctorate   9  20850\n",
       "36  female  assistant   8  doctorate  14  18304\n",
       "37    male  assistant   4  doctorate   4  17095\n",
       "38    male  assistant   4  doctorate   5  16700\n",
       "39    male  assistant   4  doctorate   4  17600\n",
       "40    male  assistant   3  doctorate   4  18075\n",
       "41    male  assistant   3    masters  11  18000\n",
       "42    male  associate   0  doctorate   7  20999\n",
       "43  female  assistant   3  doctorate   3  17250\n",
       "44    male  assistant   2  doctorate   3  16500\n",
       "45    male  assistant   2  doctorate   1  16094\n",
       "46  female  assistant   2  doctorate   6  16150\n",
       "47  female  assistant   2  doctorate   2  15350\n",
       "48    male  assistant   1  doctorate   1  16244\n",
       "49  female  assistant   1  doctorate   1  16686\n",
       "50  female  assistant   1  doctorate   1  15000\n",
       "51  female  assistant   0  doctorate   2  20300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = forward_selection(data, 'sl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sl ~ rk + yr + 1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83519076053798602"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>sl</td>        <th>  R-squared:         </th> <td>   0.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   87.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 17 Feb 2017</td> <th>  Prob (F-statistic):</th> <td>1.95e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:40:07</td>     <th>  Log-Likelihood:    </th> <td> -476.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    52</td>      <th>  AIC:               </th> <td>   961.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   968.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>  1.62e+04</td> <td>  638.677</td> <td>   25.370</td> <td> 0.000</td> <td> 1.49e+04  1.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rk[T.associate]</th> <td> 4262.2847</td> <td>  882.891</td> <td>    4.828</td> <td> 0.000</td> <td> 2487.113  6037.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rk[T.full]</th>      <td> 9454.5232</td> <td>  905.830</td> <td>   10.437</td> <td> 0.000</td> <td> 7633.230  1.13e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr</th>              <td>  375.6956</td> <td>   70.918</td> <td>    5.298</td> <td> 0.000</td> <td>  233.106   518.285</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>26.224</td> <th>  Durbin-Watson:     </th> <td>   1.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  51.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.516</td> <th>  Prob(JB):          </th> <td>6.73e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.814</td> <th>  Cond. No.          </th> <td>    32.2</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     sl   R-squared:                       0.845\n",
       "Model:                            OLS   Adj. R-squared:                  0.835\n",
       "Method:                 Least Squares   F-statistic:                     87.15\n",
       "Date:                Fri, 17 Feb 2017   Prob (F-statistic):           1.95e-19\n",
       "Time:                        13:40:07   Log-Likelihood:                -476.48\n",
       "No. Observations:                  52   AIC:                             961.0\n",
       "Df Residuals:                      48   BIC:                             968.8\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept         1.62e+04    638.677     25.370      0.000      1.49e+04  1.75e+04\n",
       "rk[T.associate]  4262.2847    882.891      4.828      0.000      2487.113  6037.457\n",
       "rk[T.full]       9454.5232    905.830     10.437      0.000      7633.230  1.13e+04\n",
       "yr                375.6956     70.918      5.298      0.000       233.106   518.285\n",
       "==============================================================================\n",
       "Omnibus:                       26.224   Durbin-Watson:                   1.808\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               51.449\n",
       "Skew:                           1.516   Prob(JB):                     6.73e-12\n",
       "Kurtosis:                       6.814   Cond. No.                         32.2\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn's F Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    yr  yd  sx_female  sx_male  rk_assistant  rk_associate  rk_full  \\\n",
      "0   25  35          0        1             0             0        1   \n",
      "1   13  22          0        1             0             0        1   \n",
      "2   10  23          0        1             0             0        1   \n",
      "3    7  27          1        0             0             0        1   \n",
      "4   19  30          0        1             0             0        1   \n",
      "5   16  21          0        1             0             0        1   \n",
      "6    0  32          1        0             0             0        1   \n",
      "7   16  18          0        1             0             0        1   \n",
      "8   13  30          0        1             0             0        1   \n",
      "9   13  31          0        1             0             0        1   \n",
      "10  12  22          0        1             0             0        1   \n",
      "11  15  19          0        1             0             1        0   \n",
      "12   9  17          0        1             0             0        1   \n",
      "13   9  27          0        1             0             1        0   \n",
      "14   9  24          0        1             0             0        1   \n",
      "15   7  15          0        1             0             0        1   \n",
      "16  13  20          0        1             0             0        1   \n",
      "17  11  14          0        1             0             1        0   \n",
      "18  10  15          0        1             0             1        0   \n",
      "19   6  21          0        1             0             0        1   \n",
      "20  16  23          0        1             1             0        0   \n",
      "21   8  31          0        1             0             1        0   \n",
      "22   7  13          0        1             0             0        1   \n",
      "23   8  24          1        0             0             0        1   \n",
      "24   9  12          0        1             0             1        0   \n",
      "25   5  18          0        1             0             0        1   \n",
      "26  11  14          0        1             0             1        0   \n",
      "27   5  16          1        0             0             0        1   \n",
      "28   3   7          0        1             0             1        0   \n",
      "29   3  17          0        1             0             1        0   \n",
      "30  10  15          1        0             1             0        0   \n",
      "31  11  31          0        1             0             1        0   \n",
      "32   9  14          0        1             1             0        0   \n",
      "33   4  33          1        0             0             1        0   \n",
      "34   6  29          1        0             0             1        0   \n",
      "35   1   9          0        1             0             1        0   \n",
      "36   8  14          1        0             1             0        0   \n",
      "37   4   4          0        1             1             0        0   \n",
      "38   4   5          0        1             1             0        0   \n",
      "39   4   4          0        1             1             0        0   \n",
      "40   3   4          0        1             1             0        0   \n",
      "41   3  11          0        1             1             0        0   \n",
      "42   0   7          0        1             0             1        0   \n",
      "43   3   3          1        0             1             0        0   \n",
      "44   2   3          0        1             1             0        0   \n",
      "45   2   1          0        1             1             0        0   \n",
      "46   2   6          1        0             1             0        0   \n",
      "47   2   2          1        0             1             0        0   \n",
      "48   1   1          0        1             1             0        0   \n",
      "49   1   1          1        0             1             0        0   \n",
      "50   1   1          1        0             1             0        0   \n",
      "51   0   2          1        0             1             0        0   \n",
      "\n",
      "    dg_doctorate  dg_masters  \n",
      "0              1           0  \n",
      "1              1           0  \n",
      "2              1           0  \n",
      "3              1           0  \n",
      "4              0           1  \n",
      "5              1           0  \n",
      "6              0           1  \n",
      "7              1           0  \n",
      "8              0           1  \n",
      "9              0           1  \n",
      "10             1           0  \n",
      "11             1           0  \n",
      "12             1           0  \n",
      "13             0           1  \n",
      "14             1           0  \n",
      "15             1           0  \n",
      "16             1           0  \n",
      "17             0           1  \n",
      "18             0           1  \n",
      "19             0           1  \n",
      "20             0           1  \n",
      "21             0           1  \n",
      "22             1           0  \n",
      "23             1           0  \n",
      "24             1           0  \n",
      "25             1           0  \n",
      "26             1           0  \n",
      "27             1           0  \n",
      "28             0           1  \n",
      "29             0           1  \n",
      "30             0           1  \n",
      "31             0           1  \n",
      "32             0           1  \n",
      "33             0           1  \n",
      "34             0           1  \n",
      "35             1           0  \n",
      "36             1           0  \n",
      "37             1           0  \n",
      "38             1           0  \n",
      "39             1           0  \n",
      "40             1           0  \n",
      "41             0           1  \n",
      "42             1           0  \n",
      "43             1           0  \n",
      "44             1           0  \n",
      "45             1           0  \n",
      "46             1           0  \n",
      "47             1           0  \n",
      "48             1           0  \n",
      "49             1           0  \n",
      "50             1           0  \n",
      "51             1           0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cols_to_transform = [\"sx\", \"rk\", \"dg\"]\n",
    "df_with_dummies = pd.get_dummies(data, columns = cols_to_transform )\n",
    "np.array(df_with_dummies.drop(\"sl\", 1))\n",
    "print(df_with_dummies.drop(\"sl\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 48.21967542,  41.81524639,   3.4130356 ,   3.4130356 ,\n",
       "         63.73033808,   0.20821107,  83.42291275,   0.24427162,   0.24427162]),\n",
       " array([  7.34137944e-09,   4.10171640e-08,   7.06039364e-02,\n",
       "          7.06039364e-02,   1.76627996e-10,   6.50149119e-01,\n",
       "          3.09650171e-12,   6.23302309e-01,   6.23302309e-01]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "f_regression(np.array(df_with_dummies.drop(\"sl\", 1)), np.array(data[\"sl\"]), center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
